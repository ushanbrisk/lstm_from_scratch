{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28063316",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from tensorboardX import SummaryWriter\n",
    "import time\n",
    "\n",
    "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1,2\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b102a9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "USE_MULTI_GPU = False\n",
    "if USE_MULTI_GPU:\n",
    "    #多gpu\n",
    "    device = torch.device(\"cuda:0,1,2\" if torch.cuda.is_available() else \"cpu\")\n",
    "    device_ids = [0, 1, 2]\n",
    "else:\n",
    "    #单gpu\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1cd66b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义一个类，继承自nn.module\n",
    "\n",
    "#输入的数据维度, [batch_size, length, feature_length]\n",
    "\n",
    "#matrix: [feature_length, hidden_length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2da38afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveCustomLSTM(nn.Module):\n",
    "    \n",
    "    #input_sz: 输入的x的维度, hidden_sz:隐藏单元h的维度\n",
    "    def __init__(self, input_sz:int, hidden_sz:int):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.input_size = input_sz\n",
    "        self.hidden_size = hidden_sz\n",
    "        \n",
    "        #i, 输入门，新增的信息  基于ht-1, xt\n",
    "        self.U_i = nn.Parameter(torch.Tensor(input_sz, hidden_sz))\n",
    "        self.V_i = nn.Parameter(torch.Tensor(hidden_sz, hidden_sz))\n",
    "        self.b_i = nn.Parameter(torch.Tensor(hidden_sz))\n",
    "        \n",
    "        #f, 遗忘门, 忘记的信息　基于ht-1, xt\n",
    "        self.U_f = nn.Parameter(torch.Tensor(input_sz, hidden_sz))\n",
    "        self.V_f = nn.Parameter(torch.Tensor(hidden_sz, hidden_sz))\n",
    "        self.b_f = nn.Parameter(torch.Tensor(hidden_sz))\n",
    "        \n",
    "        #c, 新增的信息  \n",
    "        self.U_c = nn.Parameter(torch.Tensor(input_sz, hidden_sz))\n",
    "        self.V_c = nn.Parameter(torch.Tensor(hidden_sz, hidden_sz))\n",
    "        self.b_c = nn.Parameter(torch.Tensor(hidden_sz))\n",
    "        \n",
    "        #o, 根据cell更新hidden cell\n",
    "        self.U_o = nn.Parameter(torch.Tensor(input_sz, hidden_sz))\n",
    "        self.V_o = nn.Parameter(torch.Tensor(hidden_sz, hidden_sz))\n",
    "        self.b_o = nn.Parameter(torch.Tensor(hidden_sz))\n",
    "        \n",
    "        self.init_weights()\n",
    "        \n",
    "\n",
    "    #均匀分布，初始化各个weights\n",
    "    def init_weights(self):\n",
    "        stdv = 1.0/math.sqrt(self.hidden_size)\n",
    "        for weight in self.parameters():\n",
    "            weight.data.uniform_(-stdv, stdv)\n",
    "\n",
    "\n",
    "    def forward(self, x, init_states=None):\n",
    "        '''\n",
    "        assume x.shape represents (batch_size, sequence_size, input_size)\n",
    "        '''\n",
    "\n",
    "        \n",
    "        bs, seq_sz, _ = x.size()\n",
    "\n",
    "        hidden_seq = []\n",
    "\n",
    "        \n",
    "        if init_states is None:\n",
    "            h_t, c_t = (\n",
    "                torch.zeros(bs, self.hidden_size).to(x.device),\n",
    "                torch.zeros(bs, self.hidden_size).to(x.device),\n",
    "            )                \n",
    "        else:\n",
    "            h_t, c_t = init_states\n",
    "\n",
    "        \n",
    "        for t in range(seq_sz):\n",
    "            x_t = x[:, t, :]\n",
    "\n",
    "            \n",
    "            i_t = torch.sigmoid(x_t@self.U_i + h_t@self.V_i + self.b_i)\n",
    "\n",
    "            \n",
    "            f_t = torch.sigmoid(x_t@self.U_f + h_t@self.V_f + self.b_f)\n",
    "\n",
    "            \n",
    "            o_t = torch.sigmoid(x_t@self.U_o + h_t@self.V_o + self.b_o)\n",
    "\n",
    "           \n",
    "            g_t = torch.tanh(x_t@self.U_c + h_t@self.V_c + self.b_c)\n",
    "\n",
    "            c_t = f_t * c_t + i_t * g_t\n",
    "            h_t = o_t * torch.tanh(c_t)\n",
    "\n",
    "            \n",
    "            hidden_seq.append(h_t.unsqueeze(0))\n",
    "\n",
    "        \n",
    "        hidden_seq = torch.cat(hidden_seq, dim=0)\n",
    "\n",
    "        \n",
    "        hidden_seq = hidden_seq.transpose(0, 1).contiguous()\n",
    "\n",
    "        \n",
    "        return hidden_seq, (h_t, c_t)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "615ef734",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLSTM(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_sz:int, hidden_sz:int, bidirection:bool, layer_num:int):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.input_size = input_sz\n",
    "        self.hidden_size = hidden_sz\n",
    "        self.bidirection = bidirection\n",
    "        self.layer_num = layer_num\n",
    "        \n",
    "        \n",
    "        self.U = nn.Parameter(torch.Tensor(input_sz, hidden_sz*4))\n",
    "        self.V = nn.Parameter(torch.Tensor(hidden_sz, hidden_sz*4))\n",
    "        self.b = nn.Parameter(torch.Tensor(hidden_sz*4))\n",
    "\n",
    "\n",
    "        if self.bidirection:\n",
    "            self.U2 = nn.Parameter(torch.Tensor(input_sz, hidden_sz*4))\n",
    "            self.V2 = nn.Parameter(torch.Tensor(hidden_sz, hidden_sz*4))\n",
    "            self.b2 = nn.Parameter(torch.Tensor(hidden_sz*4))\n",
    "            \n",
    "            \n",
    "       \n",
    "        if self.layer_num > 1:\n",
    "            self.layers_U = nn.Parameter(torch.Tensor(hidden_sz, hidden_sz*4*(self.layer_num - 1)))\n",
    "            self.layers_V = nn.Parameter(torch.Tensor(hidden_sz, hidden_sz*4*(self.layer_num - 1)))\n",
    "            self.layers_b = nn.Parameter(torch.Tensor(hidden_sz*4*(self.layer_num - 1)))\n",
    "\n",
    "            if self.bidirection:\n",
    "                self.layers_U2 = nn.Parameter(torch.Tensor(hidden_sz, hidden_sz*4*(self.layer_num - 1)))\n",
    "                self.layers_V2 = nn.Parameter(torch.Tensor(hidden_sz, hidden_sz*4*(self.layer_num - 1)))\n",
    "                self.layers_b2 = nn.Parameter(torch.Tensor(hidden_sz*4*(self.layer_num - 1)))\n",
    "\n",
    "        \n",
    "        self.init_weights()\n",
    "        \n",
    "\n",
    "    def init_weights(self):\n",
    "        stdv = 1.0/math.sqrt(self.hidden_size)\n",
    "        for weight in self.parameters():\n",
    "            weight.data.uniform_(-stdv, stdv)\n",
    "\n",
    "            \n",
    "    def init_ct(self, bs, device):\n",
    "        h_t, c_t = (\n",
    "            torch.zeros(bs, self.hidden_size).to(device),\n",
    "            torch.zeros(bs, self.hidden_size).to(device),\n",
    "        )\n",
    "\n",
    "        return h_t, c_t\n",
    "\n",
    "\n",
    "            \n",
    "    def forward(self, x, init_states=None):\n",
    "        '''\n",
    "        assume x.shape represents (batch_size, sequence_size, input_size)\n",
    "        '''\n",
    "\n",
    "        bs, seq_sz, _ = x.size()\n",
    "        hidden_sz = self.hidden_size \n",
    "        hidden_seq = []\n",
    "\n",
    "        if self.bidirection:\n",
    "            hidden_seq2 = []\n",
    "        \n",
    "        if self.layer_num > 1:\n",
    "            hidden_seq_layers = []  \n",
    "            if self.bidirection:\n",
    "                hidden_seq2_layers = [] \n",
    "        \n",
    "        if self.layer_num > 0:\n",
    "            last_hidden_h_layers = []  \n",
    "            last_hidden_c_layers = []  \n",
    "            if self.bidirection:\n",
    "                last_hidden2_h_layers = [] \n",
    "                last_hidden2_c_layers = [] \n",
    "                \n",
    "        \n",
    "\n",
    "        if init_states is None:\n",
    "\n",
    "            if self.bidirection:\n",
    "                h_t, c_t = self.init_ct(bs, x.device)\n",
    "                h_t2, c_t2 = self.init_ct(bs, x.device)\n",
    "            else:\n",
    "                h_t, c_t = self.init_ct(bs, x.device)\n",
    "                \n",
    "        else:\n",
    "            h_t, c_t = init_states\n",
    "            if self.bidirection:\n",
    "                h_t2, c_t2 = init_states\n",
    "            \n",
    "        \n",
    "\n",
    "        U_i, V_i, b_i = self.U[:,0:hidden_sz], self.V[:,0:hidden_sz], self.b[0:hidden_sz]\n",
    "        U_f, V_f, b_f = self.U[:,hidden_sz:hidden_sz*2], self.V[:,hidden_sz:hidden_sz*2], self.b[hidden_sz:hidden_sz*2]\n",
    "        U_c, V_c, b_c = self.U[:,hidden_sz*2:hidden_sz*3], self.V[:,hidden_sz*2:hidden_sz*3], self.b[hidden_sz*2:hidden_sz*3]\n",
    "        U_o, V_o, b_o = self.U[:,hidden_sz*3:hidden_sz*4], self.V[:,hidden_sz*3:hidden_sz*4], self.b[hidden_sz*3:hidden_sz*4]\n",
    "        \n",
    "        if self.bidirection:\n",
    "            U_i2, V_i2, b_i2 = self.U2[:,0:hidden_sz], self.V2[:,0:hidden_sz], self.b2[0:hidden_sz]\n",
    "            U_f2, V_f2, b_f2 = self.U2[:,hidden_sz:hidden_sz*2], self.V2[:,hidden_sz:hidden_sz*2], self.b2[hidden_sz:hidden_sz*2]\n",
    "            U_c2, V_c2, b_c2 = self.U2[:,hidden_sz*2:hidden_sz*3], self.V2[:,hidden_sz*2:hidden_sz*3], self.b2[hidden_sz*2:hidden_sz*3]\n",
    "            U_o2, V_o2, b_o2 = self.U2[:,hidden_sz*3:hidden_sz*4], self.V2[:,hidden_sz*3:hidden_sz*4], self.b2[hidden_sz*3:hidden_sz*4]\n",
    "        \n",
    "\n",
    "        for t in range(seq_sz):\n",
    "            x_t = x[:, t, :]            \n",
    "            gates = x_t@self.U + h_t@self.V + self.b   \n",
    "            i_t, f_t, g_t, o_t = (\n",
    "            torch.sigmoid(gates[:,0:hidden_sz]), \n",
    "            torch.sigmoid(gates[:,hidden_sz:hidden_sz*2]),\n",
    "            torch.tanh(gates[:,hidden_sz*2:hidden_sz*3]), \n",
    "            torch.sigmoid(gates[:,hidden_sz*3:hidden_sz*4]),\n",
    "            )\n",
    "\n",
    "\n",
    "            c_t = f_t * c_t + i_t * g_t\n",
    "            h_t = o_t * torch.tanh(c_t)\n",
    "\n",
    "\n",
    "            hidden_seq.append(h_t.unsqueeze(0))\n",
    "        last_hidden_h_layers.append(h_t) \n",
    "        last_hidden_c_layers.append(c_t) \n",
    "            \n",
    "            \n",
    "        if self.bidirection:\n",
    "            for t in range(seq_sz, 0, -1):\n",
    "                x_t = x[:, t-1, :]            \n",
    "                gates2 = x_t@self.U2 + h_t2@self.V2 + self.b2   \n",
    "                i_t2, f_t2, g_t2, o_t2 = (\n",
    "                torch.sigmoid(gates2[:,0:hidden_sz]), \n",
    "                torch.sigmoid(gates2[:,hidden_sz:hidden_sz*2]),\n",
    "                torch.tanh(gates2[:,hidden_sz*2:hidden_sz*3]), \n",
    "                torch.sigmoid(gates2[:,hidden_sz*3:hidden_sz*4]),\n",
    "                )\n",
    "\n",
    "\n",
    "                c_t2 = f_t2 * c_t2 + i_t2 * g_t2\n",
    "                h_t2 = o_t2 * torch.tanh(c_t2)\n",
    "\n",
    "               \n",
    "                hidden_seq2.append(h_t2.unsqueeze(0))\n",
    "            last_hidden2_h_layers.append(h_t2)\n",
    "            last_hidden2_c_layers.append(c_t2)\n",
    "\n",
    "\n",
    "        hidden_seq = torch.cat(hidden_seq, dim=0)\n",
    "        if self.bidirection:\n",
    "            hidden_seq2 = torch.cat(hidden_seq2, dim=0)\n",
    "\n",
    "            hidden_seq2 = torch.flip(hidden_seq2, dims=[0])\n",
    "        \n",
    "\n",
    "        hidden_seq = hidden_seq.transpose(0, 1).contiguous()\n",
    "        forward_hidden_seq = hidden_seq.clone()\n",
    "        forward_h_t = last_hidden_h_layers[0].clone()\n",
    "        forward_c_t = last_hidden_c_layers[0].clone()\n",
    "        \n",
    "        if self.bidirection:\n",
    "            hidden_seq2 = hidden_seq2.transpose(0,1).contiguous()\n",
    "            backward_hidden_seq = hidden_seq2.clone()\n",
    "            backward_h_t = last_hidden2_h_layers[0].clone()\n",
    "            backward_c_t = last_hidden2_c_layers[0].clone()\n",
    "                \n",
    "        \n",
    "        if self.layer_num > 1 and self.bidirection==False:\n",
    "            extend_layer_num = self.layer_num - 1\n",
    "            \n",
    "           \n",
    "            input_x = hidden_seq\n",
    "            \n",
    "\n",
    "            for layer_i in range(extend_layer_num):\n",
    "     \n",
    "                h_t, c_t = self.init_ct(bs, x.device)\n",
    "                hidden_seq_current_layer = [] \n",
    "\n",
    "                for t in range(seq_sz):\n",
    "                    x_t = input_x[:, t, :] \n",
    "                    \n",
    "\n",
    "                    gates = x_t@self.layers_U[:,layer_i*hidden_sz*4:(layer_i+1)*hidden_sz*4] + \\\n",
    "                            h_t@self.layers_V[:,layer_i*hidden_sz*4:(layer_i+1)*hidden_sz*4] + \\\n",
    "                            self.layers_b[layer_i*hidden_sz*4:(layer_i+1)*hidden_sz*4]\n",
    "                    \n",
    "                    i_t, f_t, g_t, o_t = (\n",
    "                        torch.sigmoid(gates[:,0:hidden_sz]), \n",
    "                        torch.sigmoid(gates[:,hidden_sz:hidden_sz*2]),\n",
    "                        torch.tanh(gates[:,hidden_sz*2:hidden_sz*3]), \n",
    "                        torch.sigmoid(gates[:,hidden_sz*3:hidden_sz*4]),\n",
    "                        )\n",
    "\n",
    "\n",
    "                    c_t = f_t * c_t + i_t * g_t\n",
    "                    h_t = o_t * torch.tanh(c_t)\n",
    "\n",
    "\n",
    "                    hidden_seq_current_layer.append(h_t.unsqueeze(0))\n",
    "\n",
    "                hidden_seq_current_layer = torch.cat(hidden_seq_current_layer, dim=0)\n",
    "                hidden_seq_current_layer = hidden_seq_current_layer.transpose(0, 1).contiguous()\n",
    "                \n",
    "                hidden_seq_layers.append(hidden_seq_current_layer)\n",
    "\n",
    "                input_x = hidden_seq_current_layer\n",
    "                last_hidden_h_layers.append(h_t) #多层，保留第一层最后一个h_t\n",
    "                last_hidden_c_layers.append(c_t)\n",
    "                \n",
    " \n",
    "            forward_hidden_seq = hidden_seq_layers[-1]\n",
    "            forward_h_t = torch.cat(last_hidden_h_layers, dim=-1)\n",
    "            forward_c_t = torch.cat(last_hidden_c_layers, dim=-1)\n",
    "\n",
    "        if self.layer_num > 1 and self.bidirection==True:\n",
    "            extend_layer_num = self.layer_num - 1\n",
    "            \n",
    "\n",
    "            input_x = hidden_seq2 \n",
    "            \n",
    "\n",
    "            for layer_i in range(extend_layer_num):\n",
    "                \n",
    "                \n",
    "                h_t2, c_t2 = self.init_ct(bs, x.device)\n",
    "                hidden_seq_current_layer = [] \n",
    "                \n",
    "                for t in range(seq_sz, 0, -1):\n",
    "                    x_t = input_x[:, t-1, :] \n",
    "                    \n",
    "\n",
    "                    gates2 = x_t@self.layers_U2[:,layer_i*hidden_sz*4:(layer_i+1)*hidden_sz*4] + \\\n",
    "                            h_t@self.layers_V2[:,layer_i*hidden_sz*4:(layer_i+1)*hidden_sz*4] + \\\n",
    "                            self.layers_b2[layer_i*hidden_sz*4:(layer_i+1)*hidden_sz*4]\n",
    "                    \n",
    "                    i_t2, f_t2, g_t2, o_t2 = (\n",
    "                        torch.sigmoid(gates2[:,0:hidden_sz]), \n",
    "                        torch.sigmoid(gates2[:,hidden_sz:hidden_sz*2]),\n",
    "                        torch.tanh(gates2[:,hidden_sz*2:hidden_sz*3]), \n",
    "                        torch.sigmoid(gates2[:,hidden_sz*3:hidden_sz*4]),\n",
    "                        )\n",
    "\n",
    "\n",
    "                    c_t2 = f_t2 * c_t2 + i_t2 * g_t2\n",
    "                    h_t2 = o_t2 * torch.tanh(c_t2)\n",
    "\n",
    "                    hidden_seq_current_layer.append(h_t2.unsqueeze(0))\n",
    "\n",
    "                hidden_seq_current_layer = torch.cat(hidden_seq_current_layer, dim=0)\n",
    "                hidden_seq_current_layer = torch.flip(hidden_seq_current_layer, dims=[0])\n",
    "                hidden_seq_current_layer = hidden_seq_current_layer.transpose(0, 1).contiguous()\n",
    "                \n",
    "                hidden_seq2_layers.append(hidden_seq_current_layer)\n",
    "\n",
    "                input_x = hidden_seq_current_layer\n",
    "                last_hidden2_h_layers.append(h_t2) \n",
    "                last_hidden2_c_layers.append(c_t2)\n",
    "                \n",
    "\n",
    "            backward_hidden_seq = hidden_seq2_layers[-1]\n",
    "            backward_h_t = torch.cat(last_hidden2_h_layers, dim=-1)\n",
    "            backward_c_t = torch.cat(last_hidden2_c_layers, dim=-1)\n",
    "            \n",
    "        \n",
    "        if self.bidirection:\n",
    "\n",
    "            hidden_concat = torch.cat([forward_hidden_seq, backward_hidden_seq], dim=-1)\n",
    "            h_t_concat = torch.cat([forward_h_t, backward_h_t], dim=-1)\n",
    "            c_t_concat = torch.cat([forward_c_t, backward_c_t], dim=-1)\n",
    "            return hidden_concat, (h_t_concat, c_t_concat)\n",
    "        else:\n",
    "           \n",
    "            return forward_hidden_seq, (forward_h_t, forward_c_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e3207cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49721\n"
     ]
    }
   ],
   "source": [
    "#准备文本数据\n",
    "filePath = '/home/luke/ML4T/machine-learning-for-trading/25_NLP_learning/NLP/Chinese-novel-generation/data/寒门首辅.txt'\n",
    "with open(filePath, 'r') as f:\n",
    "    text=f.read()\n",
    "\"\"\"\n",
    "可以分词，以单词为单位；也可以直接以汉字字符为单位\n",
    "\"\"\"\n",
    "#控制数据规模\n",
    "num_words_for_training = 1000000\n",
    "text = text[:min(num_words_for_training, len(text))]\n",
    "#先做分词\n",
    "lines_of_text = text.split('\\n')\n",
    "#去除头几行\n",
    "lines_of_text = lines_of_text[14:]\n",
    "print(len(lines_of_text))\n",
    "lines_of_text = [lines for lines in lines_of_text if len(lines) > 0]\n",
    "lines_of_text = [lines.strip() for lines in lines_of_text]\n",
    "#分词\n",
    "import re\n",
    "pattern = re.compile(r'\\[.*\\]')\n",
    "#将所有制定内容替换成空\n",
    "lines_of_text = [pattern.sub(\"\", lines) for lines in lines_of_text]\n",
    "pattern = re.compile(r'<.*>')\n",
    "lines_of_text = [pattern.sub(\"\", lines) for lines in lines_of_text]\n",
    "pattern = re.compile(r'\\.+')\n",
    "lines_of_text = [pattern.sub(\"\", lines) for lines in lines_of_text]\n",
    "pattern = re.compile(r' +')\n",
    "lines_of_text = [pattern.sub(\"\", lines) for lines in lines_of_text]\n",
    "pattern = re.compile(r'&#[0-9]+\\;')\n",
    "lines_of_text = [pattern.sub(\"\", lines) for lines in lines_of_text if len(lines) > 0]\n",
    "pattern = re.compile(r'&#[a-z][a-z]+')\n",
    "lines_of_text = [pattern.sub(\"\", lines) for lines in lines_of_text if len(lines) > 0]\n",
    "pattern = re.compile(r'\\\\r')\n",
    "lines_of_text = [pattern.sub(\"\", lines) for lines in lines_of_text if len(lines) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19cf51c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#创建字符索引\n",
    "def create_lookup_tables(input_data):    \n",
    "    vocab = set(input_data)    \n",
    "    # 文字到数字的映射\n",
    "    vocab_to_int = {word: idx for idx, word in enumerate(vocab)}    \n",
    "    # 数字到文字的映射\n",
    "    int_to_vocab = dict(enumerate(vocab))    \n",
    "    return vocab_to_int, int_to_vocab\n",
    "def token_lookup():\n",
    "    symbols = set(['。', '，', '“', \"”\", '；', '！', '？', '（', '）', '——', '\\n'])    \n",
    "    tokens = [\"P\", \"C\", \"Q\", \"T\", \"S\", \"E\", \"M\", \"I\", \"O\", \"D\", \"R\"]\n",
    "    return dict(zip(symbols, tokens))\n",
    "import helper\n",
    "helper.preprocess_and_save_data(''.join(lines_of_text), token_lookup, create_lookup_tables)\n",
    "#读取我们需要的数据\n",
    "int_text, vocab_to_int, int_to_vocab, token_dict = helper.load_preprocess()\n",
    "#真正index后的文本数据就在int_text里面"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0d23353",
   "metadata": {},
   "outputs": [],
   "source": [
    "#拆分数据成train/valid两组\n",
    "train_portion = 0.8\n",
    "train_size = int(train_portion*len(int_text))\n",
    "train_int_text = int_text[:train_size]\n",
    "valid_int_text = int_text[train_size:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68672074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "650751 162688\n"
     ]
    }
   ],
   "source": [
    "print(len(train_int_text), len(valid_int_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6168ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batches(int_text, batch_size, seq_length):\n",
    "    \n",
    "    # 计算有多少个batch可以创建\n",
    "    # n_batches = (len(int_text) // (batch_size * seq_length))\n",
    "\n",
    "    # 计算每一步的原始数据，和位移一位之后的数据\n",
    "    # batch_origin = np.array(int_text[: n_batches * batch_size * seq_length])\n",
    "    # batch_shifted = np.array(int_text[1: n_batches * batch_size * seq_length + 1])\n",
    "    \n",
    "    # 将位移之后的数据的最后一位，设置成原始数据的第一位，相当于在做循环\n",
    "    # batch_shifted[-1] = batch_origin[0]\n",
    "    \n",
    "    # batch_origin_reshape = np.split(batch_origin.reshape(batch_size, -1), n_batches, 1)\n",
    "    # batch_shifted_reshape = np.split(batch_shifted.reshape(batch_size, -1), n_batches, 1)\n",
    "\n",
    "    # batches = np.array(list(zip(batch_origin_reshape, batch_shifted_reshape)))\n",
    "    \n",
    "    characters_per_batch = batch_size * seq_length\n",
    "    num_batches = len(int_text) // characters_per_batch\n",
    "    \n",
    "    # clip arrays to ensure we have complete batches for inputs, targets same but moved one unit over\n",
    "    input_data = np.array(int_text[ : num_batches * characters_per_batch])\n",
    "    target_data = np.array(int_text[1 : num_batches * characters_per_batch + 1])\n",
    "    \n",
    "    inputs = input_data.reshape(batch_size, -1)\n",
    "    targets = target_data.reshape(batch_size, -1)\n",
    "\n",
    "    inputs = np.split(inputs, num_batches, 1)\n",
    "    targets = np.split(targets, num_batches, 1)\n",
    "    \n",
    "    batches = np.array(list(zip(inputs, targets)))\n",
    "    batches [-1][-1][-1][-1] = batches [0][0][0][0]\n",
    "    \n",
    "    return batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38bae0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainModel(nn.Module):\n",
    "    def __init__(self, embed_sz:int, hidden_sz:int, vocab_sz:int, bidirection:bool, layer_num:int, dropout:float):\n",
    "        super().__init__()\n",
    "        self.embed_sz = embed_sz\n",
    "        self.hidden_sz = hidden_sz\n",
    "        self.vocab_sz = vocab_sz\n",
    "        self.bidirection = bidirection\n",
    "        self.layer_num = layer_num\n",
    "\n",
    "#         input_sz = 256  #char的embedding维度\n",
    "#         hidden_sz = 64\n",
    "        self.rnn = CustomLSTM(embed_sz, hidden_sz, bidirection, layer_num)\n",
    "        self.embedding = nn.Embedding(vocab_sz, embed_sz, max_norm=1)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        if bidirection is True:\n",
    "            direct_num = 2\n",
    "        else:\n",
    "            direct_num = 1\n",
    "        \n",
    "        #输出，　D个hidden_size\n",
    "        hidden_sz_output = hidden_sz * direct_num \n",
    "        \n",
    "        #从hidden 输出到target, nn.Linear本质上就是nn.Parameter(), 用的是kaiming_init,而Parameter()用的是极端小值\n",
    "        self.output = nn.Linear(hidden_sz_output, vocab_sz)\n",
    "        \n",
    "    #src: [batch_size, length]\n",
    "    def forward(self, src):\n",
    "                \n",
    "        #src = [batch size, length]\n",
    "        #dropout after embedding layers\n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "        \n",
    "        #embedded = [batch_size, length, emb dim]\n",
    "        \n",
    "        outputs, (hidden, cell) = self.rnn(embedded)\n",
    "        \n",
    "        #outputs = [batch size, length, hidden_sz]\n",
    "        #hidden = [batch size, hidden_sz]\n",
    "        #cell = [batch size, hidden_sz]\n",
    "        \n",
    "        #[batch_size, length, vocab_sz]\n",
    "        vocab_output = self.output(outputs)\n",
    "        \n",
    "        \n",
    "        return vocab_output\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7dfbbb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "embed_sz = 64\n",
    "hidden_sz = 256\n",
    "vocab_sz = len(vocab_to_int)+1\n",
    "bidirection=True\n",
    "layer_num = 3\n",
    "dropout = 0.5\n",
    "\n",
    "#train_model = TrainModel(embed_sz, hidden_sz, vocab_sz, layer_num, dropout).to(device)\n",
    "train_model = TrainModel(embed_sz, hidden_sz, vocab_sz, bidirection, layer_num, dropout)\n",
    "\n",
    "\n",
    "if USE_MULTI_GPU:\n",
    "    #多gpu \n",
    "    #数据并行核心代码\n",
    "    train_model= nn.DataParallel(train_model,device_ids = device_ids)\n",
    "    train_model.to(device)\n",
    "else:\n",
    "    train_model.to(device)\n",
    "\n",
    "writer = SummaryWriter(log_dir='runs/logs_luke')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a7db1c64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rnn.U torch.Size([64, 1024])\n",
      "rnn.V torch.Size([256, 1024])\n",
      "rnn.b torch.Size([1024])\n",
      "rnn.U2 torch.Size([64, 1024])\n",
      "rnn.V2 torch.Size([256, 1024])\n",
      "rnn.b2 torch.Size([1024])\n",
      "rnn.layers_U torch.Size([256, 2048])\n",
      "rnn.layers_V torch.Size([256, 2048])\n",
      "rnn.layers_b torch.Size([2048])\n",
      "rnn.layers_U2 torch.Size([256, 2048])\n",
      "rnn.layers_V2 torch.Size([256, 2048])\n",
      "rnn.layers_b2 torch.Size([2048])\n",
      "embedding.weight torch.Size([4052, 64])\n",
      "output.weight torch.Size([4052, 512])\n",
      "output.bias torch.Size([4052])\n"
     ]
    }
   ],
   "source": [
    "for name, param in train_model.named_parameters():\n",
    "    print(name, param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c92fd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1024+1024\n",
    "seq_length = 32\n",
    "batches = get_batches(train_int_text, batch_size, seq_length)\n",
    "valid_batches = get_batches(valid_int_text, batch_size, seq_length)\n",
    "batches = torch.tensor(batches).to(device)\n",
    "valid_batches = torch.tensor(valid_batches).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f2d70b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rnn.U torch.Size([64, 1024])\n",
      "rnn.V torch.Size([256, 1024])\n",
      "rnn.b torch.Size([1024])\n",
      "rnn.U2 torch.Size([64, 1024])\n",
      "rnn.V2 torch.Size([256, 1024])\n",
      "rnn.b2 torch.Size([1024])\n",
      "rnn.layers_U torch.Size([256, 2048])\n",
      "rnn.layers_V torch.Size([256, 2048])\n",
      "rnn.layers_b torch.Size([2048])\n",
      "rnn.layers_U2 torch.Size([256, 2048])\n",
      "rnn.layers_V2 torch.Size([256, 2048])\n",
      "rnn.layers_b2 torch.Size([2048])\n",
      "embedding.weight torch.Size([4052, 64])\n",
      "output.weight torch.Size([4052, 512])\n",
      "output.bias torch.Size([4052])\n",
      "Number of parameter: 5.10M\n",
      "Number of parameter: 5.10M\n"
     ]
    }
   ],
   "source": [
    "for name, param in train_model.named_parameters():\n",
    "    print(name, param.shape)\n",
    "\n",
    "total = sum([param.nelement() for param in train_model.parameters()])\n",
    "print(\"Number of parameter: %.2fM\" % (total/1e6))\n",
    "total = sum([param.nelement() for param in train_model.parameters()])\n",
    "print(\"Number of parameter: %.2fM\" % (total/1e6))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "103f7afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#自定义l1, l2类\n",
    "class L1_Loss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(L1_Loss, self).__init__();\n",
    " \n",
    "    def forward(self, weights):\n",
    "        abs_difference = torch.abs(weights)\n",
    "        loss_value = torch.mean(abs_difference)\n",
    "        return loss_value\n",
    "\n",
    "class L2_Loss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(L2_Loss, self).__init__();\n",
    " \n",
    "    def forward(self, weights):\n",
    "        square_difference = torch.square(weights)\n",
    "        loss_value = torch.mean(square_difference)\n",
    "        return loss_value\n",
    "\n",
    "#参考https://stackoverflow.com/questions/42704283/l1-l2-regularization-in-pytorch\n",
    "# l1_lambda = 0.001\n",
    "# l1_norm = sum(torch.linalg.norm(p, 1) for p in train_model.parameters())\n",
    "# loss = loss + l1_lambda * l1_norm\n",
    "\n",
    "\n",
    "\n",
    "#定义损失函数\n",
    "criterion_CEL = nn.CrossEntropyLoss()\n",
    "criterion_L1 = L1_Loss()\n",
    "criterion_L2 = L2_Loss()\n",
    "\n",
    "#定义优化器\n",
    "optimizer = torch.optim.Adam(train_model.parameters(), lr=1e-2)\n",
    "\n",
    "# Initialize the hidden weights\n",
    "optimizer.zero_grad()  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "480007b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#每做完一次epoch, 计算一次evaluate()\n",
    "#区别在于，train还需要优化器optimizer, 以及clip等\n",
    "def train(model, batches, optimizer, criterion_CEL, criterion_L1, l1_lambda, criterion_L2, l2_lambda):\n",
    "    epoch_loss = 0\n",
    "    l1_loss = 0\n",
    "    l2_loss = 0\n",
    "    cel_loss = 0\n",
    "    for batch_i, (x, y) in enumerate(batches):\n",
    "        optimizer.zero_grad() #优化器每次都清零\n",
    "        y_pred = model(x)\n",
    "#         print(y.shape)\n",
    "#         print(y_pred.shape)\n",
    "        output_dim = y_pred.shape[-1]\n",
    "        target_pred = y_pred.view(-1, output_dim)\n",
    "        target_true = y.view(-1)\n",
    "        #这个loss包含了l1, l2\n",
    "        loss = criterion_CEL(target_pred, target_true) + l1_lambda*sum(criterion_L1(p) for name, p in train_model.named_parameters() if 'embed' not in name) + \\\n",
    "                l2_lambda*sum(criterion_L2(p) for name, p in train_model.named_parameters() if 'embed' not in name)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        batch_loss = loss.item()\n",
    "        epoch_loss += batch_loss\n",
    "        \n",
    "        l1_loss += sum(criterion_L1(p) for name, p in train_model.named_parameters() if 'embed' not in name)\n",
    "        l2_loss += sum(criterion_L2(p) for name, p in train_model.named_parameters() if 'embed' not in name)\n",
    "        cel_loss += criterion_CEL(target_pred, target_true).item()\n",
    "    return epoch_loss/len(batches), cel_loss/len(batches), l1_loss/len(batches), l2_loss/len(batches)\n",
    "    \n",
    "def evaluate(model, batches, criterion_CEL, criterion_L1, l1_lambda, criterion_L2, l2_lambda):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    l1_loss = 0\n",
    "    l2_loss = 0\n",
    "    cel_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_i, (x,y) in enumerate(batches):\n",
    "            y_pred = model(x)\n",
    "            output_dim = y_pred.shape[-1]\n",
    "            target_pred = y_pred.view(-1, output_dim)\n",
    "            target_true = y.view(-1)\n",
    "            #evalute的loss不包含l1, l2?\n",
    "            loss = criterion_CEL(target_pred, target_true) + l1_lambda*sum(criterion_L1(p) for name, p in train_model.named_parameters() if 'embed' not in name) + \\\n",
    "                l2_lambda*sum(criterion_L2(p) for name, p in train_model.named_parameters() if 'embed' not in name)\n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "            l1_loss += sum(criterion_L1(p) for name, p in train_model.named_parameters() if 'embed' not in name)\n",
    "            l2_loss += sum(criterion_L2(p) for name, p in train_model.named_parameters() if 'embed' not in name)\n",
    "            cel_loss += criterion_CEL(target_pred, target_true).item()\n",
    "    return epoch_loss/len(batches), cel_loss/len(batches), l1_loss/len(batches), l2_loss/len(batches)\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ae34624e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0/150 0m 4s train_loss = 7.078, valid_loss = 6.580\n",
      "Epoch   1/150 0m 4s train_loss = 6.415, valid_loss = 6.612\n",
      "Epoch   2/150 0m 5s train_loss = 6.357, valid_loss = 6.296\n",
      "Epoch   3/150 0m 4s train_loss = 5.832, valid_loss = 5.646\n",
      "Epoch   4/150 0m 4s train_loss = 5.284, valid_loss = 5.363\n",
      "Epoch   5/150 0m 4s train_loss = 4.923, valid_loss = 4.911\n",
      "Epoch   6/150 0m 4s train_loss = 4.594, valid_loss = 4.732\n",
      "Epoch   7/150 0m 4s train_loss = 4.220, valid_loss = 4.341\n",
      "Epoch   8/150 0m 4s train_loss = 4.080, valid_loss = 4.126\n",
      "Epoch   9/150 0m 4s train_loss = 3.720, valid_loss = 3.937\n",
      "Epoch  10/150 0m 4s train_loss = 3.412, valid_loss = 3.707\n",
      "Epoch  11/150 0m 5s train_loss = 3.201, valid_loss = 3.576\n",
      "Epoch  12/150 0m 5s train_loss = 3.028, valid_loss = 3.403\n",
      "Epoch  13/150 0m 5s train_loss = 2.881, valid_loss = 3.486\n",
      "Epoch  14/150 0m 5s train_loss = 2.789, valid_loss = 3.234\n",
      "Epoch  15/150 0m 5s train_loss = 2.525, valid_loss = 2.946\n",
      "Epoch  16/150 0m 5s train_loss = 2.281, valid_loss = 2.751\n",
      "Epoch  17/150 0m 5s train_loss = 2.286, valid_loss = 3.104\n",
      "Epoch  18/150 0m 5s train_loss = 2.125, valid_loss = 2.502\n",
      "Epoch  19/150 0m 4s train_loss = 1.829, valid_loss = 2.297\n",
      "Epoch  20/150 0m 5s train_loss = 1.650, valid_loss = 2.171\n",
      "Epoch  21/150 0m 5s train_loss = 1.511, valid_loss = 2.032\n",
      "Epoch  22/150 0m 5s train_loss = 1.423, valid_loss = 2.084\n",
      "Epoch  23/150 0m 4s train_loss = 1.437, valid_loss = 1.914\n",
      "Epoch  24/150 0m 4s train_loss = 1.279, valid_loss = 1.808\n",
      "Epoch  25/150 0m 4s train_loss = 1.179, valid_loss = 1.728\n",
      "Epoch  26/150 0m 4s train_loss = 1.108, valid_loss = 1.672\n",
      "Epoch  27/150 0m 5s train_loss = 1.050, valid_loss = 1.615\n",
      "Epoch  28/150 0m 4s train_loss = 1.343, valid_loss = 5.996\n",
      "Epoch  29/150 0m 4s train_loss = 3.642, valid_loss = 2.947\n",
      "Epoch  30/150 0m 4s train_loss = 2.060, valid_loss = 2.241\n",
      "Epoch  31/150 0m 4s train_loss = 1.553, valid_loss = 1.927\n",
      "Epoch  32/150 0m 4s train_loss = 1.323, valid_loss = 1.762\n",
      "Epoch  33/150 0m 4s train_loss = 1.193, valid_loss = 1.667\n",
      "Epoch  34/150 0m 4s train_loss = 1.106, valid_loss = 1.598\n",
      "Epoch  35/150 0m 4s train_loss = 1.042, valid_loss = 1.548\n",
      "Epoch  36/150 0m 4s train_loss = 0.992, valid_loss = 1.509\n",
      "Epoch  37/150 0m 4s train_loss = 0.951, valid_loss = 1.477\n",
      "Epoch  38/150 0m 4s train_loss = 1.143, valid_loss = 1.702\n",
      "Epoch  39/150 0m 4s train_loss = 1.086, valid_loss = 1.573\n",
      "Epoch  40/150 0m 4s train_loss = 0.960, valid_loss = 1.480\n",
      "Epoch  41/150 0m 4s train_loss = 0.891, valid_loss = 1.429\n",
      "Epoch  42/150 0m 4s train_loss = 0.847, valid_loss = 1.393\n",
      "Epoch  43/150 0m 4s train_loss = 0.815, valid_loss = 1.365\n",
      "Epoch  44/150 0m 4s train_loss = 0.789, valid_loss = 1.344\n",
      "Epoch  45/150 0m 4s train_loss = 0.766, valid_loss = 1.325\n",
      "Epoch  46/150 0m 4s train_loss = 0.746, valid_loss = 1.306\n",
      "Epoch  47/150 0m 4s train_loss = 0.728, valid_loss = 1.292\n",
      "Epoch  48/150 0m 4s train_loss = 0.711, valid_loss = 1.277\n",
      "Epoch  49/150 0m 4s train_loss = 0.695, valid_loss = 1.263\n",
      "Epoch  50/150 0m 4s train_loss = 0.680, valid_loss = 1.249\n",
      "Epoch  51/150 0m 4s train_loss = 0.665, valid_loss = 1.237\n",
      "Epoch  52/150 0m 4s train_loss = 0.651, valid_loss = 1.226\n",
      "Epoch  53/150 0m 5s train_loss = 0.639, valid_loss = 1.215\n",
      "Epoch  54/150 0m 5s train_loss = 0.626, valid_loss = 1.205\n",
      "Epoch  55/150 0m 4s train_loss = 0.614, valid_loss = 1.195\n",
      "Epoch  56/150 0m 4s train_loss = 0.603, valid_loss = 1.185\n",
      "Epoch  57/150 0m 4s train_loss = 0.591, valid_loss = 1.176\n",
      "Epoch  58/150 0m 4s train_loss = 1.001, valid_loss = 3.212\n",
      "Epoch  59/150 0m 4s train_loss = 2.079, valid_loss = 2.075\n",
      "Epoch  60/150 0m 4s train_loss = 1.286, valid_loss = 1.615\n",
      "Epoch  61/150 0m 4s train_loss = 0.952, valid_loss = 1.398\n",
      "Epoch  62/150 0m 4s train_loss = 0.800, valid_loss = 1.277\n",
      "Epoch  63/150 0m 4s train_loss = 0.723, valid_loss = 1.222\n",
      "Epoch  64/150 0m 4s train_loss = 0.675, valid_loss = 1.182\n",
      "Epoch  65/150 0m 4s train_loss = 0.642, valid_loss = 1.154\n",
      "Epoch  66/150 0m 4s train_loss = 0.617, valid_loss = 1.132\n",
      "Epoch  67/150 0m 4s train_loss = 0.597, valid_loss = 1.114\n",
      "Epoch  68/150 0m 4s train_loss = 0.580, valid_loss = 1.102\n",
      "Epoch  69/150 0m 4s train_loss = 0.566, valid_loss = 1.089\n",
      "Epoch  70/150 0m 4s train_loss = 0.553, valid_loss = 1.078\n",
      "Epoch  71/150 0m 4s train_loss = 0.541, valid_loss = 1.067\n",
      "Epoch  72/150 0m 4s train_loss = 0.530, valid_loss = 1.058\n",
      "Epoch  73/150 0m 4s train_loss = 0.520, valid_loss = 1.047\n",
      "Epoch  74/150 0m 4s train_loss = 0.510, valid_loss = 1.040\n",
      "Epoch  75/150 0m 4s train_loss = 0.501, valid_loss = 1.034\n",
      "Epoch  76/150 0m 4s train_loss = 0.493, valid_loss = 1.027\n",
      "Epoch  77/150 0m 4s train_loss = 0.486, valid_loss = 1.021\n",
      "Epoch  78/150 0m 4s train_loss = 0.479, valid_loss = 1.013\n",
      "Epoch  79/150 0m 4s train_loss = 0.471, valid_loss = 1.005\n",
      "Epoch  80/150 0m 4s train_loss = 0.465, valid_loss = 0.999\n",
      "Epoch  81/150 0m 4s train_loss = 0.458, valid_loss = 0.997\n",
      "Epoch  82/150 0m 4s train_loss = 0.454, valid_loss = 0.995\n",
      "Epoch  83/150 0m 4s train_loss = 0.449, valid_loss = 0.986\n",
      "Epoch  84/150 0m 4s train_loss = 0.443, valid_loss = 0.985\n",
      "Epoch  85/150 0m 4s train_loss = 0.439, valid_loss = 0.978\n",
      "Epoch  86/150 0m 4s train_loss = 0.434, valid_loss = 0.974\n",
      "Epoch  87/150 0m 4s train_loss = 0.429, valid_loss = 0.971\n",
      "Epoch  88/150 0m 4s train_loss = 0.424, valid_loss = 0.961\n",
      "Epoch  89/150 0m 4s train_loss = 0.419, valid_loss = 0.961\n",
      "Epoch  90/150 0m 4s train_loss = 0.416, valid_loss = 0.962\n",
      "Epoch  91/150 0m 4s train_loss = 0.413, valid_loss = 0.959\n",
      "Epoch  92/150 0m 5s train_loss = 0.411, valid_loss = 0.954\n",
      "Epoch  93/150 0m 4s train_loss = 0.408, valid_loss = 0.952\n",
      "Epoch  94/150 0m 4s train_loss = 0.404, valid_loss = 0.948\n",
      "Epoch  95/150 0m 4s train_loss = 0.400, valid_loss = 0.945\n",
      "Epoch  96/150 0m 5s train_loss = 0.395, valid_loss = 0.941\n",
      "Epoch  97/150 0m 5s train_loss = 0.391, valid_loss = 0.943\n",
      "Epoch  98/150 0m 5s train_loss = 0.387, valid_loss = 0.935\n",
      "Epoch  99/150 0m 5s train_loss = 0.384, valid_loss = 0.930\n",
      "Epoch 100/150 0m 5s train_loss = 0.380, valid_loss = 0.931\n",
      "Epoch 101/150 0m 5s train_loss = 0.376, valid_loss = 0.924\n",
      "Epoch 102/150 0m 5s train_loss = 0.372, valid_loss = 0.918\n",
      "Epoch 103/150 0m 5s train_loss = 0.370, valid_loss = 0.920\n",
      "Epoch 104/150 0m 5s train_loss = 0.367, valid_loss = 0.915\n",
      "Epoch 105/150 0m 4s train_loss = 0.366, valid_loss = 0.908\n",
      "Epoch 106/150 0m 4s train_loss = 0.362, valid_loss = 0.905\n",
      "Epoch 107/150 0m 4s train_loss = 0.360, valid_loss = 0.902\n",
      "Epoch 108/150 0m 4s train_loss = 0.356, valid_loss = 0.902\n",
      "Epoch 109/150 0m 4s train_loss = 0.354, valid_loss = 0.896\n",
      "Epoch 110/150 0m 4s train_loss = 0.352, valid_loss = 0.889\n",
      "Epoch 111/150 0m 4s train_loss = 0.348, valid_loss = 0.886\n",
      "Epoch 112/150 0m 4s train_loss = 0.344, valid_loss = 0.880\n",
      "Epoch 113/150 0m 4s train_loss = 0.341, valid_loss = 0.881\n",
      "Epoch 114/150 0m 4s train_loss = 0.339, valid_loss = 0.871\n",
      "Epoch 115/150 0m 4s train_loss = 0.336, valid_loss = 0.875\n",
      "Epoch 116/150 0m 4s train_loss = 0.334, valid_loss = 0.874\n",
      "Epoch 117/150 0m 4s train_loss = 0.332, valid_loss = 0.869\n",
      "Epoch 118/150 0m 4s train_loss = 0.330, valid_loss = 0.865\n",
      "Epoch 119/150 0m 4s train_loss = 0.328, valid_loss = 0.859\n",
      "Epoch 120/150 0m 4s train_loss = 0.327, valid_loss = 0.861\n",
      "Epoch 121/150 0m 4s train_loss = 0.326, valid_loss = 0.860\n",
      "Epoch 122/150 0m 4s train_loss = 0.324, valid_loss = 0.856\n",
      "Epoch 123/150 0m 4s train_loss = 0.324, valid_loss = 0.866\n",
      "Epoch 124/150 0m 4s train_loss = 0.321, valid_loss = 0.862\n",
      "Epoch 125/150 0m 4s train_loss = 0.319, valid_loss = 0.856\n",
      "Epoch 126/150 0m 4s train_loss = 0.318, valid_loss = 0.854\n",
      "Epoch 127/150 0m 4s train_loss = 0.318, valid_loss = 0.865\n",
      "Epoch 128/150 0m 4s train_loss = 2.909, valid_loss = 4.308\n",
      "Epoch 129/150 0m 4s train_loss = 2.904, valid_loss = 2.807\n",
      "Epoch 130/150 0m 4s train_loss = 1.870, valid_loss = 2.115\n",
      "Epoch 131/150 0m 4s train_loss = 1.374, valid_loss = 1.746\n",
      "Epoch 132/150 0m 4s train_loss = 1.103, valid_loss = 1.530\n",
      "Epoch 133/150 0m 4s train_loss = 0.942, valid_loss = 1.399\n",
      "Epoch 134/150 0m 4s train_loss = 0.839, valid_loss = 1.311\n",
      "Epoch 135/150 0m 4s train_loss = 0.766, valid_loss = 1.249\n",
      "Epoch 136/150 0m 4s train_loss = 0.713, valid_loss = 1.203\n",
      "Epoch 137/150 0m 4s train_loss = 0.672, valid_loss = 1.168\n",
      "Epoch 138/150 0m 4s train_loss = 0.640, valid_loss = 1.138\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 139/150 0m 4s train_loss = 0.613, valid_loss = 1.116\n",
      "Epoch 140/150 0m 4s train_loss = 0.590, valid_loss = 1.095\n",
      "Epoch 141/150 0m 4s train_loss = 0.571, valid_loss = 1.078\n",
      "Epoch 142/150 0m 4s train_loss = 0.554, valid_loss = 1.064\n",
      "Epoch 143/150 0m 4s train_loss = 0.539, valid_loss = 1.050\n",
      "Epoch 144/150 0m 4s train_loss = 0.526, valid_loss = 1.037\n",
      "Epoch 145/150 0m 4s train_loss = 0.513, valid_loss = 1.025\n",
      "Epoch 146/150 0m 4s train_loss = 0.501, valid_loss = 1.016\n",
      "Epoch 147/150 0m 4s train_loss = 0.491, valid_loss = 1.007\n",
      "Epoch 148/150 0m 4s train_loss = 0.482, valid_loss = 0.999\n",
      "Epoch 149/150 0m 4s train_loss = 0.474, valid_loss = 0.994\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 150\n",
    "l1_lambda = 0.5\n",
    "l2_lambda = 0.5\n",
    "\n",
    "\n",
    "for epoch_i in range(num_epochs):\n",
    "    start_time = time.time()\n",
    "    train_loss, train_loss_cel, train_loss_l1, train_loss_l2 = train(train_model, batches, optimizer, criterion_CEL, criterion_L1, l1_lambda,  criterion_L2, l2_lambda)\n",
    "    \n",
    "    valid_loss, valid_loss_cel, valid_loss_l1, valid_loss_l2 = evaluate(train_model, valid_batches, criterion_CEL, criterion_L1, l1_lambda,  criterion_L2, l2_lambda)\n",
    "    \n",
    "    end_time = time.time()    \n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    writer.add_scalar('train_loss', train_loss, global_step=epoch_i)\n",
    "    writer.add_scalar('valid_loss', valid_loss, global_step=epoch_i)\n",
    "\n",
    "    writer.add_scalar('train_loss_cel', train_loss_cel, global_step=epoch_i)\n",
    "    writer.add_scalar('valid_loss_cel', valid_loss_cel, global_step=epoch_i)\n",
    "\n",
    "    writer.add_scalar('train_loss_l1', train_loss_l1, global_step=epoch_i)\n",
    "    writer.add_scalar('valid_loss_l1', valid_loss_l1, global_step=epoch_i)\n",
    "\n",
    "    writer.add_scalar('train_loss_l2', train_loss_l2, global_step=epoch_i)\n",
    "    writer.add_scalar('valid_loss_l2', valid_loss_l2, global_step=epoch_i)\n",
    "    \n",
    "    \n",
    "    for name, param in train_model.named_parameters():\n",
    "        writer.add_histogram(\n",
    "        \"train/{}\".format(name), param.detach().cpu().numpy(), epoch_i\n",
    "        )\n",
    "        if param.grad is not None:\n",
    "            writer.add_histogram(\n",
    "                \"train/{}/grad\".format(name), param.grad.detach().cpu().numpy(), epoch_i\n",
    "            )\n",
    "\n",
    "    print('Epoch {:>3}/{} {}m {}s train_loss = {:.3f}, valid_loss = {:.3f}'.format(\n",
    "        epoch_i,\n",
    "        num_epochs,\n",
    "        epoch_mins,\n",
    "        epoch_secs,\n",
    "        train_loss,\n",
    "        valid_loss\n",
    "    ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "539aa923",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 2, 3072, 32])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batches.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7280d84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#生成文本\n",
    "\n",
    "prime_word = '大'\n",
    "gen_length = 500\n",
    "gen_sentences = [prime_word]\n",
    "\n",
    "# 开始生成文本\n",
    "for n in range(gen_length):\n",
    "    dyn_input = [[vocab_to_int[word] for word in gen_sentences[-seq_length:]]]\n",
    "    dyn_seq_length = len(dyn_input[0])\n",
    "    \n",
    "    #dyn_input: [1, L]\n",
    "    y_gen = train_model(torch.tensor(dyn_input).to(device))\n",
    "    \n",
    "    #y_gen shape: [1, L, vocab_sz]\n",
    "    y_gen_last = y_gen[:,-1,:].detach().cpu().numpy().reshape(-1)\n",
    "    \n",
    "    \n",
    "    y_gen_prob = np.exp(y_gen_last)/sum(np.exp(y_gen_last))\n",
    "    \n",
    "#    max_idx = np.argmax(y_gen_last.view(-1).cpu().detach().numpy())\n",
    "    rand_idx = np.random.choice(len(int_to_vocab)+1, p=y_gen_prob)\n",
    "\n",
    "    pred_word = int_to_vocab[rand_idx]\n",
    "    gen_sentences.append(pred_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9ec9c5f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "大宝祠锹门丫童头，可理牟斌虽心中有种足，就看如何对写起，从粮里还是能没有狎妓可以看他在考，化人和王陈家和二文在城这么日子王守仁现桥起的。谢慎觉得没一世冤掌呢？诗作杜磅涂的气，便是来己的锦爷，哼了下业，端该问，可想沉声手安感，你一个秀什功名人出了。”王守仁是说道不归一就是看来的。”那油种时候，此言我你说，直奔知之题。谢慎对了’叔父虚，要行口道。只虽说道这时老吧。”孔教续也是想拜破，出来谭府修宴上还是很攫啊。如果没有大秀左两马年抢置时招。谢慎小友布。倒是天了状品都是要做个银钱太就的，故而在贡，北考之贵，之曾然事情倒，便或留举。谢慎这三方也没有用解。宁益能除了不过的设运使大头可是也是。解而不过设尊的雇佣几如果你是说。这主不让守么，这萧话，那道这这位公子，转移回了。”“哦宿一个方生看，便明代举啊。”“老公夫咯得大人也错。””王家徐虎儿清门，早这红，摆了小气。”谢慎的过便和沈雁道听听拱道：“你若是要就是我们！”谢丕这小娘为突何，一个。你说了过腋学生，再造尽喜悦气一声，若是我了？”兄！我是大兄，你的不许太貌穆会招。”与崔兄，我的好小童个晚生不喜欢，你说，嬉子我们明人裁日，偷读的名生。不同阳没最重要不\n"
     ]
    }
   ],
   "source": [
    "# 将标点符号还原\n",
    "novel = ''.join(gen_sentences)\n",
    "for key, token in token_dict.items():\n",
    "    ending = ' ' if key in ['\\n', '（', '“'] else ''\n",
    "#     novel = novel.replace(token.lower(), key)\n",
    "    novel = novel.replace(token, key)\n",
    "# novel = novel.replace('\\n ', '\\n')\n",
    "# novel = novel.replace('（ ', '（')\n",
    "\n",
    "print(novel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "11aa15da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#生成文本的时候，还是要给点随机性，不然会重复"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "227e73f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#后续思考，cell, hidden区别，如何改进，　gru, \n",
    "#seq2seq如何编写\n",
    "#transformer\n",
    "#xlnet, gpt, bert等等\n",
    "\n",
    "#还是要NER,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "559ba130",
   "metadata": {},
   "outputs": [],
   "source": [
    "#先看下embedding向量，是否合理\n",
    "embedding_weight = train_model.embedding.weight.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ebc66f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "int_to_embed = {}\n",
    "for i in range(len(embedding_weight)):\n",
    "    int_to_embed[i] = embedding_weight[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "df22a44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "输入是embed向量，输出是index\n",
    "'''\n",
    "def pick_nearest_embed(embed):\n",
    "    closest_dist = 1e20\n",
    "    closest_index = -1\n",
    "    for i in range(len(embedding_weight)):\n",
    "        embed_candidate = embedding_weight[i]\n",
    "        dist = np.mean(np.square(embed - embed_candidate))\n",
    "        if dist==0:\n",
    "            continue\n",
    "        if closest_dist > dist:\n",
    "            closest_dist = dist\n",
    "            closest_index = i\n",
    "    return closest_index\n",
    "'''\n",
    "输入是字符，输出是字符\n",
    "'''        \n",
    "def pick_nearest_vocab(char):\n",
    "    char_i = vocab_to_int[char]\n",
    "    embed_i = int_to_embed[char_i] \n",
    "    closest_vocab = int_to_vocab[pick_nearest_embed(embed_i)]\n",
    "    return closest_vocab\n",
    "        \n",
    "#(char1,char2) -> (char3, ?)\n",
    "def pick_relative_vocab(char1, char2, char3):\n",
    "    char_1_embed = embedding_weight[vocab_to_int[char1]]\n",
    "    char_2_embed = embedding_weight[vocab_to_int[char2]]\n",
    "    char_3_embed = embedding_weight[vocab_to_int[char3]]\n",
    "    \n",
    "    char_4_embed_pre = char_2_embed - char_1_embed + char_3_embed\n",
    "    return int_to_vocab[pick_nearest_embed(char_4_embed_pre)]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2abc5065",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'我'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " pick_nearest_vocab('你')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "472e792c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'生'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_to_vocab[pick_nearest_embed(embedding_weight[vocab_to_int['官']])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7c2e76e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'大'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pick_relative_vocab('男', '大', '女')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d370d28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "char_1_embed = embedding_weight[vocab_to_int['白']]\n",
    "char_2_embed = embedding_weight[vocab_to_int['黑']]\n",
    "char_3_embed = embedding_weight[vocab_to_int['天']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d083087e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.015094513"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.square(char_3_embed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "84e2e418",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([3.95e+03, 0.00e+00, 0.00e+00, 1.00e+00, 2.00e+01, 3.70e+01,\n",
       "        2.70e+01, 1.50e+01, 1.00e+00, 1.00e+00]),\n",
       " array([1.0612193e-16, 1.7078136e-01, 3.4156272e-01, 5.1234406e-01,\n",
       "        6.8312544e-01, 8.5390681e-01, 1.0246881e+00, 1.1954695e+00,\n",
       "        1.3662509e+00, 1.5370322e+00, 1.7078136e+00], dtype=float32),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "length = []\n",
    "for i in range(len(embedding_weight)):\n",
    "    length.append(np.mean(np.square(embedding_weight[i])))\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26dbca7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28588fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#用相对距离来衡量的话，发现　char1, char2, char3, 对应都是char2, 说明char2太特殊了，　也就是向量太sparse了，embed sz = 300\n",
    "改成64试试看呢"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
